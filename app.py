import streamlit as st
import os
from deepseek_client import DeepSeekClient
from utils import init_session_state, render_markdown, add_message
from doc_parser import GuideParser
from config import DEEPSEEK_API_KEY
from typing import List
from db import Database
import uuid
from lecture_manager import LectureManager

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Java Webå­¦ç”Ÿç®¡ç†ç³»ç»Ÿå¼€å‘æŒ‡å—",
    page_icon="ğŸ“š",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
init_session_state()

# åˆå§‹åŒ–æ•™æ¡ˆç®¡ç†å™¨
lecture_manager = LectureManager()

# åˆå§‹åŒ–æ–‡æ¡£è§£æå™¨
if 'guide_parser' not in st.session_state:
    try:
        # è·å–å¯ç”¨çš„æ•™æ¡ˆ
        available_lectures = lecture_manager.get_available_lectures()
        
        if not available_lectures:
            st.error("æœªæ‰¾åˆ°ä»»ä½•æ•™æ¡ˆæ–‡ä»¶")
            st.stop()
            
        # é»˜è®¤åŠ è½½ç¬¬ä¸€ä¸ªæ•™æ¡ˆ
        st.session_state.guide_parser = lecture_manager.load_lecture(available_lectures[0]["path"])
        st.session_state.current_lecture = available_lectures[0]["path"]
    except Exception as e:
        st.error(f"åˆå§‹åŒ–æ–‡æ¡£è§£æå™¨å¤±è´¥: {str(e)}")
        st.stop()

# åˆå§‹åŒ–AIå“åº”å­˜å‚¨
if 'ai_responses' not in st.session_state:
    st.session_state.ai_responses = {}

# åˆå§‹åŒ–å¯¹è¯å†å²
if 'chat_histories' not in st.session_state:
    st.session_state.chat_histories = {}

# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
try:
    if not DEEPSEEK_API_KEY:
        api_key = st.text_input("è¯·è¾“å…¥ DeepSeek API å¯†é’¥:", type="password")
        if not api_key:
            st.warning("è¯·è¾“å…¥ DeepSeek API å¯†é’¥ä»¥ç»§ç»­")
            st.stop()
    else:
        api_key = DEEPSEEK_API_KEY
        
    deepseek_client = DeepSeekClient(api_key=api_key)
except Exception as e:
    st.error(f"åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
    st.stop()

# åˆå§‹åŒ–æ•°æ®åº“
db = Database()

# åœ¨ä¼šè¯çŠ¶æ€åˆå§‹åŒ–éƒ¨åˆ†æ·»åŠ 
if 'session_id' not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# ä¾§è¾¹æ å¯¼èˆª
with st.sidebar:
    st.title("æ•™æ¡ˆé€‰æ‹©")
    
    # è·å–å¯ç”¨çš„æ•™æ¡ˆ
    available_lectures = lecture_manager.get_available_lectures()
    
    if not available_lectures:
        st.error("æœªæ‰¾åˆ°ä»»ä½•æ•™æ¡ˆæ–‡ä»¶")
        st.stop()
    
    # é€‰æ‹©æ•™æ¡ˆ
    selected_lecture = st.selectbox(
        "é€‰æ‹©å­¦ä¹ å†…å®¹",
        options=available_lectures,
        format_func=lambda x: x["name"]
    )
    
    # åŠ è½½é€‰ä¸­çš„æ•™æ¡ˆ
    if 'current_lecture' not in st.session_state or \
       st.session_state.current_lecture != selected_lecture["path"]:
        try:
            st.session_state.guide_parser = lecture_manager.load_lecture(selected_lecture["path"])
            st.session_state.current_lecture = selected_lecture["path"]
            # æ¸…é™¤ä¹‹å‰çš„å¯¹è¯å†å²
            st.session_state.chat_histories = {}
            st.session_state.learning_history = []
        except Exception as e:
            st.error(f"åŠ è½½æ•™æ¡ˆå¤±è´¥: {str(e)}")
            st.stop()
    
    st.title("å­¦ä¹ å¯¼èˆª")
    
    try:
        # ä¸»ç« èŠ‚é€‰æ‹©
        main_section = st.selectbox(
            "é€‰æ‹©ç« èŠ‚",
            options=list(st.session_state.guide_parser.root.keys())
        )
        
        # å­ç« èŠ‚é€‰æ‹©
        if main_section:
            current_section = st.session_state.guide_parser.root[main_section]
            if current_section.children:
                sub_section = st.selectbox(
                    "é€‰æ‹©å°èŠ‚",
                    options=[node.title for node in current_section.children]
                )
            else:
                sub_section = None
    except Exception as e:
        st.error(f"åŠ è½½å¯¼èˆªå¤±è´¥: {str(e)}")
        st.stop()

# å†…å®¹åŒºåŸŸ
if main_section:
    st.title(main_section)

    try:
        if sub_section:
            # è·å–å½“å‰å­èŠ‚ç‚¹
            current_node = next(
                node for node in current_section.children 
                if node.title == sub_section
            )
            
            # æ˜¾ç¤ºå­æ ‡é¢˜
            st.subheader(sub_section)
            
            # ç”Ÿæˆå½“å‰é¡µé¢çš„å”¯ä¸€æ ‡è¯†
            page_id = f"{main_section}_{sub_section}"
            
            # åˆå§‹åŒ–å½“å‰é¡µé¢çš„å¯¹è¯å†å²
            if page_id not in st.session_state.chat_histories:
                st.session_state.chat_histories[page_id] = []
            
            # åˆå§‹åŒ–æ¶ˆæ¯å ä½ç¬¦
            if "message_placeholder" not in st.session_state:
                st.session_state.message_placeholder = st.empty()
            
            # æ˜¾ç¤ºå†å²å¯¹è¯
            for message in st.session_state.chat_histories[page_id]:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # å¦‚æœè¿˜æ²¡æœ‰å¯¹è¯å†å²ï¼Œæ˜¾ç¤ºåˆå§‹æé—®éƒ¨åˆ†
            if not st.session_state.chat_histories[page_id]:
                # å°†å†…å®¹ä½œä¸ºæç¤ºè¯
                edited_prompt = st.text_area(
                    "ç¼–è¾‘æç¤ºè¯æ¥è·å–AIæŒ‡å¯¼",
                    value=current_node.prompt if current_node.prompt else current_node.content,
                    height=150,
                    key=f"prompt_{page_id}"
                )
                
                if st.button("è·å–AIæŒ‡å¯¼", key=f"button_{page_id}"):
                    try:
                        with st.chat_message("user"):
                            st.markdown(edited_prompt)
                        
                        with st.chat_message("assistant"):
                            message_placeholder = st.empty()
                            full_response = ""
                            
                            # æ„å»ºå®Œæ•´çš„å¯¹è¯å†å²
                            messages = st.session_state.chat_histories[page_id] + [
                                {"role": "user", "content": edited_prompt}
                            ]
                            
                            # æµå¼è¾“å‡ºå“åº”
                            for response_chunk in deepseek_client.get_streaming_response(
                                messages=messages,
                                current_topic=f"{selected_lecture['name']} - {main_section} - {sub_section}"
                            ):
                                full_response += response_chunk
                                message_placeholder.markdown(full_response + "â–Œ")
                            
                            message_placeholder.markdown(full_response)
                            
                            # ä¿å­˜åˆ°å¯¹è¯å†å²
                            st.session_state.chat_histories[page_id].extend([
                                {"role": "user", "content": edited_prompt},
                                {"role": "assistant", "content": full_response}
                            ])
                            
                            # ä¿å­˜åˆ°å­¦ä¹ å†å²
                            st.session_state.learning_history.append({
                                "section": main_section,
                                "subsection": sub_section,
                                "prompt": edited_prompt,
                                "response": full_response
                            })
                            
                            # ä½¿ç”¨æ–°çš„ rerun æ–¹æ³•
                            st.rerun()
                            
                    except Exception as e:
                        st.error(f"è·å–AIå“åº”å¤±è´¥: {str(e)}")
            
            # ä¿®æ”¹æ˜¾ç¤ºå»ºè®®çš„è¿½åŠ æé—®éƒ¨åˆ†
            if st.session_state.chat_histories[page_id]:
                # åˆå§‹åŒ–é—®é¢˜çŠ¶æ€
                if f"questions_{page_id}" not in st.session_state:
                    st.session_state[f"questions_{page_id}"] = deepseek_client.generate_follow_up_questions(
                        chat_history=st.session_state.chat_histories[page_id],
                        current_topic=f"{main_section} - {sub_section}"
                    )
                
                # æ˜¾ç¤ºå»ºè®®çš„è¿½åŠ æé—®æŒ‰é’®
                st.write("å»ºè®®çš„è¿½åŠ æé—®ï¼š")
                
                # å‚ç›´æ˜¾ç¤ºé¢˜æŒ‰é’®
                for idx, question in enumerate(st.session_state[f"questions_{page_id}"]):
                    if st.button(
                        question,
                        key=f"suggest_{page_id}_{len(st.session_state.chat_histories[page_id])}_{idx}",
                        use_container_width=True  # ä½¿æŒ‰é’®å®½åº¦å¡«æ»¡
                    ):
                        try:
                            with st.chat_message("user"):
                                st.markdown(question)
                                
                            with st.chat_message("assistant"):
                                message_placeholder = st.empty()
                                full_response = ""
                                
                                # æ„å»ºå®Œæ•´çš„å¯¹è¯å†å²
                                messages = st.session_state.chat_histories[page_id] + [
                                    {"role": "user", "content": question}
                                ]
                                
                                # æµå¼è¾“å‡ºå“åº”
                                for response_chunk in deepseek_client.get_streaming_response(
                                    messages=messages,
                                    current_topic=f"{selected_lecture['name']} - {main_section} - {sub_section}"
                                ):
                                    full_response += response_chunk
                                    message_placeholder.markdown(full_response + "â–Œ")
                                
                                message_placeholder.markdown(full_response)
                                
                                # ä¿å­˜åˆ°å¯¹è¯å†å²
                                st.session_state.chat_histories[page_id].extend([
                                    {"role": "user", "content": question},
                                    {"role": "assistant", "content": full_response}
                                ])
                                
                                # ä¿å­˜åˆ°å­¦ä¹ å†å²
                                st.session_state.learning_history.append({
                                    "section": main_section,
                                    "subsection": sub_section,
                                    "prompt": question,
                                    "response": full_response
                                })
                                
                                # ç”Ÿæˆæ–°çš„é—®é¢˜é›†
                                st.session_state[f"questions_{page_id}"] = deepseek_client.generate_follow_up_questions(
                                    chat_history=st.session_state.chat_histories[page_id],
                                    current_topic=f"{main_section} - {sub_section}"
                                )
                                
                                # ä½¿ç”¨æ–°çš„ rerun æ–¹æ³•
                                st.rerun()
                        except Exception as e:
                            st.error(f"è·å–AIå“åº”å¤±è´¥: {str(e)}")
                
                # åœ¨æœ€åæ˜¾ç¤º"æ¢ä¸€ç»„é—®é¢˜"æŒ‰é’®
                if st.button(
                    "æ¢ä¸€ç»„é—®é¢˜", 
                    key=f"refresh_questions_{page_id}",
                    use_container_width=True  # ä½¿æŒ‰é’®å®½åº¦å¡«æ»¡
                ):
                    st.session_state[f"questions_{page_id}"] = deepseek_client.generate_follow_up_questions(
                        chat_history=st.session_state.chat_histories[page_id],
                        current_topic=f"{main_section} - {sub_section}"
                    )
                    st.rerun()
                
                # æ·»åŠ ä¸€äº›é—´è·
                st.write("")
                
                # è‡ªä¹‰æé—®è¾“å…¥æ¡†
                st.write("æˆ–è€…è‡ªå®šä¹‰æé—®ï¼š")
                follow_up = st.text_area(
                    "è¿›ä¸€æ­¥æé—®",
                    value="",  # è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œç¡®ä¿æ¯æ¬¡éƒ½æ˜¯ç©ºç™½è¾“å…¥æ¡†
                    height=100,
                    key=f"follow_up_{page_id}_{len(st.session_state.chat_histories[page_id])}"  # åŠ¨æ€keyï¼Œç¡®ä¿æ¯æ¬¡éƒ½æ˜¯æ–°çš„è¾“å…¥æ¡†
                )
                
                if st.button("å‘é€æé—®", key=f"follow_up_button_{page_id}_{len(st.session_state.chat_histories[page_id])}"):
                    if follow_up.strip():  # åªæœ‰å½“è¾“å…¥ä¸ä¸ºç©ºæ—¶æ‰å¤„ç†
                        try:
                            with st.chat_message("user"):
                                st.markdown(follow_up)
                                
                            with st.chat_message("assistant"):
                                message_placeholder = st.empty()
                                full_response = ""
                                
                                # æ„å»ºå®Œæ•´çš„å¯¹è¯å†
                                messages = st.session_state.chat_histories[page_id] + [
                                    {"role": "user", "content": follow_up}
                                ]
                                
                                # æµå¼è¾“å‡ºå“åº”
                                for response_chunk in deepseek_client.get_streaming_response(
                                    messages=messages,
                                    current_topic=f"{selected_lecture['name']} - {main_section} - {sub_section}"
                                ):
                                    full_response += response_chunk
                                    message_placeholder.markdown(full_response + "â–Œ")
                                
                                message_placeholder.markdown(full_response)
                                
                                # ä¿å­˜åˆ°å¯¹è¯å†å²
                                st.session_state.chat_histories[page_id].extend([
                                    {"role": "user", "content": follow_up},
                                    {"role": "assistant", "content": full_response}
                                ])
                                
                                # ä¿å­˜å­¦ä¹ å†å²
                                st.session_state.learning_history.append({
                                    "section": main_section,
                                    "subsection": sub_section,
                                    "prompt": follow_up,
                                    "response": full_response
                                })
                                
                                # ä½¿ç”¨æ–°çš„ rerun æ–¹æ³•
                                st.rerun()
                                
                        except Exception as e:
                            st.error(f"è·å–AIå“åº”å¤±è´¥: {str(e)}")
        else:
            # æ˜¾ç¤ºä¸»ç« èŠ‚å†…å®¹
            st.markdown(render_markdown(current_section.content), unsafe_allow_html=True)

    except Exception as e:
        st.error(f"æ˜¾ç¤ºå†…å®¹å¤±è´¥: {str(e)}")

# æ˜¾ç¤ºå­¦ä¹ å†å²
if st.sidebar.checkbox("æ˜¾ç¤ºå­¦ä¹ å†å²"):
    st.sidebar.subheader("å­¦ä¹ å†å²")
    for idx, item in enumerate(st.session_state.learning_history):
        with st.sidebar.expander(
            f"{item['section']} - {item['subsection']}"
        ):
            st.write("æç¤ºè¯ï¼š", item['prompt'])
            st.write("AIå›åº”ï¼š", item['response']) 